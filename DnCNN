import matplotlib.pyplot as plt
import torch
import torch.nn.init as init
import torch.nn.functional as F
import torchvision
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets, models
import time
import numpy as np
import cv2
from skimage import io
import math
from scipy.linalg import orth

# GPU setting
print(torch.cuda.is_available())
if torch.cuda.is_available():
    torch.cuda.current_device()
    torch.cuda.device(0)
    torch.cuda.device_count()
    torch.cuda.get_device_name(0)

    # setting device on GPU if available, else CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

# add noise
def addnoise(img,types,n,mean=0,sd=1,lam=1,multi=False):
    image = img.clone()
    #image = img
    c,h,w = image.shape
    
    if types == 'original':
        pass
    
    elif types == 'saltpepper':
        n = n // 2
        for k in range(n):
            i = int(np.random.random() * image.shape[1])
            j = int(np.random.random() * image.shape[2])
            if image.ndim == 2:
                image[j,i] = 1
            elif img.ndim == 3:
                image[0,j,i]= 1
                image[1,j,i]= 1
                image[2,j,i]= 1
        for k in range(n):
            i = int(np.random.random() * image.shape[1])
            j = int(np.random.random() * image.shape[2])
            if image.ndim == 2:
                image[j,i] = 0
            elif img.ndim == 3:
                image[0,j,i]= 0
                image[1,j,i]= 0
                image[2,j,i]= 0
                
    else:
        mask = np.random.choice((0,1),size=(c,h,w),p=[1-n/h/w,n/h/w])
        
        if types == 'gaussian':
            noise = np.random.normal(loc=mean, scale=sd, size=(c,h,w))

        if types == 'poisson':
            noise = np.random.poisson(lam=lam, size=(c,h,w))

        if types == 'uniform':
            noise = np.random.random(size=(c,h,w))
        
        if types == 'exponential':
            noise = np.random.exponential(scale=lam,size=(c,h,w))
            
        if types == 'lognormal':
            noise = np.random.lognormal(mean=mean,sigma=sd,size=(c,h,w))
            
        if types == 'rayleigh':
            noise = np.random.rayleigh(scale=lam,size=(c,h,w))
      
        noise = noise * mask
        
        if multi == False:
            image = image + noise
        if multi == True:
            image = image + image * noise
  
    return image
    
# create dataset    
def dataset(data,size,seed=0,noise_type='gaussian',noise_num=250,multi=False):
  img = []
  img_gt = []
  img_noise = []
  if size == 'all':
    for k,(j,_) in enumerate(data):
        img_gt.append(j)
        imgnoise = addnoise(j,types=noise_type,n=noise_num,multi=multi)
        img_noise.append(imgnoise)
  else:
    np.random.seed(seed)
    index = np.random.randint(0,len(data),size=size)
    for i in index:
        img.append(data[i])
        
    for k,(j,_) in enumerate(img):
        img_gt.append(j)
        imgnoise = addnoise(j,types=noise_type,n=noise_num,multi=multi)
        img_noise.append(imgnoise)
  return img_gt,img_noise    
  
# show image
def imgshow(data,fig_num,fig_size):
  plt.figure(figsize=fig_size)
  for i,j in enumerate(data):
      ax = plt.subplot(math.ceil(len(data)/50), 5, i+1 ) # 行，列，索引（需从1开始）
      to_img = transforms.ToPILImage()
      n = to_img(j)
      ax.imshow(n) 
      #ax.set_title(name[i])
      ax.set_xticks([]) # 设置刻度为无
      ax.set_yticks([])
      if i+1 == fig_num:
        break
  return plt.show()  
  

# create DnCNN
class DnCNN(nn.Module):

    def __init__(self, depth=12, n_channels=64, image_channels=3, use_bnorm=True, kernel_size=3):
        super(DnCNN, self).__init__()
        
        kernel_size = 3  
        padding = 1  
        layers = [] 

        layers.append(nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))
        layers.append(nn.ReLU())
        for _ in range(depth-2):
            layers.append(nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True))
            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.9))
            layers.append(nn.ReLU())
        layers.append(nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=True))
        self.dncnn = nn.Sequential(*layers).to(device)
        self._initialize_weights() 
        
    def forward(self, x):
        x = x.to(device)
        y = x.to(device)
        out = self.dncnn(x).to(device)
        return y-out

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.orthogonal_(m.weight)
                print('init weight')
                if m.bias is not None:
                    init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                init.constant_(m.weight, 1)
                init.constant_(m.bias, 0)

dncnn = DnCNN()
print(dncnn)

def gaussian(window_size, sigma):
    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
    return gauss/gauss.sum()
 
def create_window(window_size, channel=3):
    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
    return window
 
# SSIM
def ssim(img1, img2, window_size=11, window=None, size_average=True, full=False, val_range=None):
    # Value range can be different from 255. Other common ranges are 1 (sigmoid) and 2 (tanh).
    if val_range is None:
        if torch.max(img1) > 128:
            max_val = 255
        else:
            max_val = 1
 
        if torch.min(img1) < -0.5:
            min_val = -1
        else:
            min_val = 0
        L = max_val - min_val
    else:
        L = val_range
 
    padd = 0
    (_, channel, height, width) = img1.size()
    if window is None:
        real_size = min(window_size, height, width)
        window = create_window(real_size, channel=channel).to(img1.device)
 
    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)
    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)
 
    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2
 
    sigma1_sq = F.conv2d(img1 * img1, window, padding=padd, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2 * img2, window, padding=padd, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1 * img2, window, padding=padd, groups=channel) - mu1_mu2
 
    C1 = (0.01 * L) ** 2
    C2 = (0.03 * L) ** 2
 
    v1 = 2.0 * sigma12 + C2
    v2 = sigma1_sq + sigma2_sq + C2
    cs = torch.mean(v1 / v2)  # contrast sensitivity
 
    ssim_map = ((2 * mu1_mu2 + C1) * v1) / ((mu1_sq + mu2_sq + C1) * v2)
 
    if size_average:
        ret = ssim_map.mean()
    else:
        ret = ssim_map.mean(1).mean(1).mean(1)
 
    if full:
        return ret, cs
    return ret
 
# Classes to re-use window
class SSIM(torch.nn.Module):
    def __init__(self, window_size=11, size_average=True, val_range=None):
        super(SSIM, self).__init__()
        self.window_size = window_size
        self.size_average = size_average
        self.val_range = val_range
 
        # Assume 1 channel for SSIM
        self.channel = 1
        self.window = create_window(window_size)
 
    def forward(self, img1, img2):
        (_, channel, _, _) = img1.size()
 
        if channel == self.channel and self.window.dtype == img1.dtype:
            window = self.window
        else:
            window = create_window(self.window_size, channel).to(img1.device).type(img1.dtype)
            self.window = window
            self.channel = channel
        ssimloss = ssim(img1, img2, window=window, window_size=self.window_size, size_average=self.size_average)
 
        return ssimloss
        
        

def net_training(data_noise,data_gt,test_noise,test_gt,epoch,lr,criterion,name,net=dncnn,optimizer='adam',fig_num=range(0,100,9),loss_min=0):

  Epoch = epoch
  LOSS = []
  if criterion == 'MSE':
    Criterion = nn.MSELoss()
  if criterion == 'SSIM':
    Criterion = SSIM()
    criterion = '1-SSIM'
  if criterion == 'PSNR':
    Criterion = PSRN()
    criterion = '1-PSNR'
  Criterion = Criterion.to(device)

  if optimizer == 'adam':
    optimizer = torch.optim.Adam(net.parameters(),lr=lr)
  if optimizer == 'sgd':
    optimizer = optim.SGD(net.parameters(), lr=lr)

  print("Training loop:")
  for idx in range(0,Epoch):
    for input, target in zip(data_noise,data_gt):
      optimizer.zero_grad()   # zero the gradient buffers
      input = input.float().to(device)
      target = target.float().to(device)
      #output = input - net(input)
      output = net(input)
      noise = (input - target)
      if criterion == 'MSE':
        loss = Criterion(output,noise)
      if criterion == '1-SSIM' or criterion == '1-PSRN':
        loss = 1 - Criterion(output,noise)
      loss.backward()
      optimizer.step()   # Does the update
    #if idx % 500 == 0:
      #print("Epoch {: >8} Loss: {}".format(idx, loss.data.numpy()))
    #print("Epoch {: >8} Loss: {}".format(idx, loss.cpu()))
    LOSS.append(loss.cpu().data.numpy())
    
    # show the training image: ground-truth image, noisy image, denoising image, predicted noise, ground-truth noise
    #if idx in fig_num:
    #  for j,k in zip(data_noise,data_gt):
    #    to_img = transforms.ToPILImage()
    #    j = j.float().to(device)
    #    k = k.float().to(device)
    #    #pred = j - net(j)   # the denoising image
    #    pred = net(j)  # output is the noise
    #    plt.figure(figsize=(20,100))
    #    for n,m,p in zip(pred,j,k):
    #      n = n.to(device)
    #      ax = plt.subplot(1, 5, 1) 
    #      img = to_img(p)
    #      plt.imshow(img)
    #      ax.set_xticks([]) 
    #      ax.set_yticks([])
    #      ax = plt.subplot(1, 5, 2)
    #      img = to_img(m)
    #      plt.imshow(img)
    #      ax.set_xticks([]) 
    #      ax.set_yticks([])
    #      ax = plt.subplot(1, 5, 3)
    #      img = to_img(m-n)
    #      plt.imshow(img)
    #      ax.set_xticks([]) 
    #      ax.set_yticks([])
    #      ax = plt.subplot(1, 5, 4)
    #      img = to_img(n)
    #      plt.imshow(img)
    #      ax.set_xticks([]) 
    #      ax.set_yticks([])
    #      ax = plt.subplot(1, 5, 5)
    #      img = to_img(m-p)
    #      plt.imshow(img)
    #      ax.set_xticks([]) 
    #      ax.set_yticks([])
    #      break
    #    plt.show()
    #    break
    # the stopping strategy
    if loss < loss_min:
      break
  path = name + '.pkl'
  torch.save(net,path) 
  plt.plot(LOSS,'-')
  plt.ylabel(criterion)
  plt.xlabel('Epoch')
  #plt.yscale('log')
  plt.show()
  mse = []
  
  # show the last epoch result of training set
  for input,target in zip(data_noise,data_gt):
    input = input.float().to(device)
    target = target.float().to(device)
    output = net(input)
    denoising = input - output
    mse.append(Criterion(denoising,target).cpu().data.numpy())
  MSE = np.mean(mse)
  PRSN = round(20 * math.log10(1 / math.sqrt(MSE)),3)
  print('training PRSN: ',PRSN)
  
  # show the performance of test set
  for input,target in zip(test_noise,test_gt):
    input = input.float().to(device)
    target = target.float().to(device)
    output = net(input)
    denoising = input - output
    mse.append(Criterion(denoising,target).cpu().data.numpy())
  MSE = np.mean(mse)
  PRSN = round(20 * math.log10(1 / math.sqrt(MSE)),3)
  print('test PRSN: ',PRSN)
  
  # show the last epoch training image of training set
  for j,k in zip(data_noise,data_gt):
    to_img = transforms.ToPILImage()
    j = j.float().to(device)
    k = k.float().to(device)
    #pred = j - net(j)
    pred = net(j)
    plt.figure(figsize=(20,100))
    count = 25
    i = 0
    for n,m,p in zip(pred,j,k):
      i += 1
      if i == count:
          n = n.to(device)
          ax = plt.subplot(1, 5, 1) 
          img = to_img(p)
          plt.imshow(img)
          ax.set_xticks([]) 
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 2)
          img = to_img(m)
          plt.imshow(img)
          ax.set_xticks([])
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 3)
          img = to_img(m-n)
          plt.imshow(img)
          ax.set_xticks([]) 
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 4)
          img = to_img(n)
          plt.imshow(img)
          ax.set_xticks([]) 
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 5)
          img = to_img(m-p)
          plt.imshow(img)
          ax.set_xticks([]) 
          ax.set_yticks([])
          plt.show()
          break        
  print('========'*5)
  
  # show the predict performance of test set
  for j,k in zip(test_noise,test_gt):
    to_img = transforms.ToPILImage()
    j = j.float().to(device)
    k = k.float().to(device)
    #pred = j - net(j)
    pred = net(j)
    plt.figure(figsize=(20,100))
    count = 10
    i = 0
    for n,m,p in zip(pred,j,k):
      i += 1
      if i == count:
          n = n.to(device)
          ax = plt.subplot(1, 5, 1) 
          img = to_img(p)
          plt.imshow(img)
          ax.set_xticks([]) # 设置刻度为无
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 2)
          img = to_img(m)
          plt.imshow(img)
          ax.set_xticks([]) # 设置刻度为无
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 3)
          img = to_img(m-n)
          plt.imshow(img)
          ax.set_xticks([]) # 设置刻度为无
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 4)
          img = to_img(n)
          plt.imshow(img)
          ax.set_xticks([]) # 设置刻度为无
          ax.set_yticks([])
          ax = plt.subplot(1, 5, 5)
          img = to_img(m-p)
          plt.imshow(img)
          ax.set_xticks([]) # 设置刻度为无
          ax.set_yticks([])
          break
  return LOSS
  
  
# load image and add addictive Gaussian noise
train_gt_gau,train_noise_gau = dataset(train_set,size=1024,seed=123,noise_type='gaussian',noise_num=1000,multi=False)
test_gt_gau,test_noise_gau = dataset(test_set,size=256,seed=123,noise_type='gaussian',noise_num=1000,multi=False)

batch_size = 64
train_noise_gau_batch = DataLoader(train_noise_gau, batch_size=batch_size, shuffle=False)
train_gt_gau_batch = DataLoader(train_gt_gau, batch_size=batch_size, shuffle=False)

test_noise_gau_batch = DataLoader(test_noise_gau, batch_size=batch_size, shuffle=False,num_workers=0)
test_gt_gau_batch = DataLoader(test_gt_gau, batch_size=batch_size, shuffle=False,num_workers=0)

# DnCNN training
a=net_training(train_noise_gau_batch,train_gt_gau_batch,test_noise_gau_batch,test_gt_gau_batch,net=dncnn,
        epoch=200,optimizer='adam',criterion='MSE',lr=0.0001,fig_num=range(0,200,9),loss_min=1e-6,
        name='rayleighAdd1000')
